{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üõ£Ô∏è Train Pothole Detector (RDD2022) on Colab GPU\n",
                "\n",
                "This notebook automates the training of a YOLOv12 model for Pothole Detection using the sekilab RDD2022 dataset.\n",
                "\n",
                "**Steps:**\n",
                "1.  Setup Environment (GPU Check)\n",
                "2.  Install Dependencies\n",
                "3.  Download & Prepare Dataset\n",
                "4.  Train Model\n",
                "5.  Download Weights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Check GPU\n",
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Install Dependencies\n",
                "!pip install ultralytics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Download Dataset (RDD2022 - India Only)\n",
                "# We will use the Kaggle dataset directly or download from a source.\n",
                "# For simplicity, we assume you upload the 'RDD2022_India.zip' to Colab Files manually \n",
                "# OR mount Drive if you have it there.\n",
                "\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Copy dataset from Drive to Colab local (faster training)\n",
                "# NOTE: Make sure the file uploaded to Drive/Colab is named exactly 'RDD2022_India.zip'\n",
                "!cp '/content/drive/MyDrive/RDD2022_India.zip' '/content/dataset.zip'\n",
                "!unzip -q '/content/dataset.zip' -d '/content/dataset'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Data Preparation Script (Same as local)\n",
                "import os\n",
                "import glob\n",
                "import xml.etree.ElementTree as ET\n",
                "import shutil\n",
                "import random\n",
                "from tqdm import tqdm\n",
                "import yaml\n",
                "\n",
                "# CONFIG\n",
                "BASE_DIR = '/content'\n",
                "# Update path to match the unzipped structure of RDD2022_India.zip\n",
                "# Usually it unzips into 'RDD2022_India/India/train...' or similar. Adjusting recursively just in case.\n",
                "RAW_IMAGES_DIR = glob.glob(\"/content/dataset/**/train/images\", recursive=True)[0]\n",
                "RAW_XML_DIR = glob.glob(\"/content/dataset/**/train/annotations/xmls\", recursive=True)[0]\n",
                "\n",
                "PROCESSED_DIR = os.path.join(BASE_DIR, \"dataset\", \"processed_rdd\")\n",
                "IMAGES_TRAIN_DIR = os.path.join(PROCESSED_DIR, \"images\", \"train\")\n",
                "IMAGES_VAL_DIR = os.path.join(PROCESSED_DIR, \"images\", \"val\")\n",
                "LABELS_TRAIN_DIR = os.path.join(PROCESSED_DIR, \"labels\", \"train\")\n",
                "LABELS_VAL_DIR = os.path.join(PROCESSED_DIR, \"labels\", \"val\")\n",
                "\n",
                "CLASSES = ['D00', 'D01', 'D10', 'D11', 'D20', 'D40', 'D43', 'D44']\n",
                "CLASS_MAP = {name: i for i, name in enumerate(CLASSES)}\n",
                "SPLIT_RATIO = 0.8\n",
                "\n",
                "def convert_xml_to_yolo(xml_file, output_txt_path):\n",
                "    try:\n",
                "        tree = ET.parse(xml_file)\n",
                "        root = tree.getroot()\n",
                "        size = root.find('size')\n",
                "        w = int(size.find('width').text)\n",
                "        h = int(size.find('height').text)\n",
                "        yolo_lines = []\n",
                "        for obj in root.findall('object'):\n",
                "            cls_name = obj.find('name').text\n",
                "            if cls_name not in CLASS_MAP: continue\n",
                "            cls_id = CLASS_MAP[cls_name]\n",
                "            xmlbox = obj.find('bndbox')\n",
                "            b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), \n",
                "                 float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
                "            dw = 1.0 / w\n",
                "            dh = 1.0 / h\n",
                "            x = (b[0] + b[1]) / 2.0 * dw\n",
                "            y = (b[2] + b[3]) / 2.0 * dh\n",
                "            bw = (b[1] - b[0]) * dw\n",
                "            bh = (b[3] - b[2]) * dh\n",
                "            yolo_lines.append(f\"{cls_id} {x:.6f} {y:.6f} {bw:.6f} {bh:.6f}\")\n",
                "        if yolo_lines:\n",
                "            with open(output_txt_path, 'w') as f:\n",
                "                f.write('\\n'.join(yolo_lines))\n",
                "            return True\n",
                "        return False\n",
                "    except Exception as e:\n",
                "        print(e)\n",
                "        return False\n",
                "\n",
                "print(\"üöÄ Starting Data Prep...\")\n",
                "for d in [IMAGES_TRAIN_DIR, IMAGES_VAL_DIR, LABELS_TRAIN_DIR, LABELS_VAL_DIR]:\n",
                "    os.makedirs(d, exist_ok=True)\n",
                "    \n",
                "xml_files = glob.glob(os.path.join(RAW_XML_DIR, \"*.xml\"))\n",
                "dataset = []\n",
                "for xml_path in xml_files:\n",
                "    basename = os.path.splitext(os.path.basename(xml_path))[0]\n",
                "    jpg_path = os.path.join(RAW_IMAGES_DIR, basename + \".jpg\")\n",
                "    if os.path.exists(jpg_path):\n",
                "        dataset.append((jpg_path, xml_path))\n",
                "\n",
                "random.shuffle(dataset)\n",
                "split = int(len(dataset) * SPLIT_RATIO)\n",
                "train, val = dataset[:split], dataset[split:]\n",
                "\n",
                "def process(subset, img_dir, lbl_dir):\n",
                "    for img, xml in tqdm(subset):\n",
                "        if convert_xml_to_yolo(xml, os.path.join(lbl_dir, os.path.splitext(os.path.basename(img))[0] + \".txt\")):\n",
                "            shutil.copy(img, os.path.join(img_dir, os.path.basename(img)))\n",
                "\n",
                "process(train, IMAGES_TRAIN_DIR, LABELS_TRAIN_DIR)\n",
                "process(val, IMAGES_VAL_DIR, LABELS_VAL_DIR)\n",
                "\n",
                "# Create YAML\n",
                "data_yaml = {\n",
                "    'path': PROCESSED_DIR,\n",
                "    'train': 'images/train',\n",
                "    'val': 'images/val',\n",
                "    'names': {i: n for i, n in enumerate(CLASSES)}\n",
                "}\n",
                "with open('/content/rdd_data.yaml', 'w') as f:\n",
                "    yaml.dump(data_yaml, f)\n",
                "    \n",
                "print(\"‚úÖ Ready for Training!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Train Model\n",
                "!yolo task=detect mode=train model=yolo12n.pt data='/content/rdd_data.yaml' epochs=50 imgsz=640"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Download Weights\n",
                "from google.colab import files\n",
                "files.download('/content/runs/detect/train/weights/best.pt')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}